{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Load and Preprocess Images\n",
    "class ImageDataset:\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        Initialize dataset with image transformations for AlexNet\n",
    "        \n",
    "        Args:\n",
    "        root_dir (str): Path to the directory containing images\n",
    "        \"\"\"\n",
    "        # Standard image transformations for AlexNet\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Load images\n",
    "        self.dataset = ImageFolder(root=root_dir, transform=self.transform)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "# STEP 1: Feature Extraction with AlexNet\n",
    "class AlexNetFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize pre-trained AlexNet and extract feature hooks\n",
    "        \"\"\"\n",
    "        # Load pre-trained AlexNet\n",
    "        self.model = models.alexnet(pretrained=True)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Dictionary to store activations\n",
    "        self.activations = {}\n",
    "        \n",
    "        # Register hooks for specified layers\n",
    "        self.layers = {\n",
    "            'conv1': self.model.features[0],\n",
    "            'conv2': self.model.features[3],\n",
    "            'conv3': self.model.features[6],\n",
    "            'conv4': self.model.features[8],\n",
    "            'conv5': self.model.features[10],\n",
    "            'fc6': self.model.classifier[1],\n",
    "            'fc7': self.model.classifier[4]\n",
    "        }\n",
    "        \n",
    "        self.hooks = {}\n",
    "        for name, layer in self.layers.items():\n",
    "            self.hooks[name] = layer.register_forward_hook(\n",
    "                self._get_activation(name)\n",
    "            )\n",
    "        \n",
    "    def _get_activation(self, name):\n",
    "        \"\"\"\n",
    "        Create hook to capture layer activations\n",
    "        \n",
    "        Args:\n",
    "        name (str): Name of the layer\n",
    "        \n",
    "        Returns:\n",
    "        hook function to store activations\n",
    "        \"\"\"\n",
    "        def hook(module, input, output):\n",
    "            self.activations[name] = output.detach().cpu().numpy()\n",
    "        return hook\n",
    "    \n",
    "    def extract_features(self, images):\n",
    "        \"\"\"\n",
    "        Extract features for given images\n",
    "        \n",
    "        Args:\n",
    "        images (torch.Tensor): Batch of preprocessed images\n",
    "        \n",
    "        Returns:\n",
    "        dict: Activation vectors for each specified layer\n",
    "        \"\"\"\n",
    "        # Forward pass to trigger hooks\n",
    "        with torch.no_grad():\n",
    "            self.model(images)\n",
    "        \n",
    "        # Vectorize activations\n",
    "        feature_vectors = {}\n",
    "        for name, activation in self.activations.items():\n",
    "            # Flatten and normalize activations\n",
    "            feature_vectors[name] = activation.reshape(activation.shape[0], -1)\n",
    "        \n",
    "        return feature_vectors\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Remove hooks when done\n",
    "        \"\"\"\n",
    "        for hook in self.hooks.values():\n",
    "            hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Create Representational Dissimilarity Matrix (RDM)\n",
    "def create_rdm(feature_vectors):\n",
    "    \"\"\"\n",
    "    Create Representational Dissimilarity Matrix\n",
    "    \n",
    "    Args:\n",
    "    feature_vectors (np.ndarray): Feature vectors for images\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Representational Dissimilarity Matrix\n",
    "    \"\"\"\n",
    "    return euclidean_distances(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Visualization Functions\n",
    "def plot_rdm(rdm, title, class_labels=None):\n",
    "    \"\"\"\n",
    "    Plot Representational Dissimilarity Matrix\n",
    "    \n",
    "    Args:\n",
    "    rdm (np.ndarray): Representational Dissimilarity Matrix\n",
    "    title (str): Plot title\n",
    "    class_labels (list, optional): Labels for each image class\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(rdm, cmap='viridis', square=True, cbar=True)\n",
    "    plt.title(f'Representational Dissimilarity Matrix - {title}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'rdm_{title}.png')\n",
    "    plt.close()\n",
    "\n",
    "def perform_mds(rdm, class_labels):\n",
    "    \"\"\"\n",
    "    Perform Multidimensional Scaling\n",
    "    \n",
    "    Args:\n",
    "    rdm (np.ndarray): Representational Dissimilarity Matrix\n",
    "    class_labels (list): Labels for each image class\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: MDS coordinates\n",
    "    \"\"\"\n",
    "    # Perform MDS\n",
    "    mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "    mds_coords = mds.fit_transform(rdm)\n",
    "    \n",
    "    # Create color map\n",
    "    unique_labels = list(set(class_labels))\n",
    "    color_map = plt.cm.get_cmap('viridis')\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    for label in unique_labels:\n",
    "        mask = np.array(class_labels) == label\n",
    "        plt.scatter(\n",
    "            mds_coords[mask, 0], \n",
    "            mds_coords[mask, 1], \n",
    "            label=f'Class {label}', \n",
    "            color=color_map(label/len(unique_labels))\n",
    "        )\n",
    "    \n",
    "    plt.title('Multidimensional Scaling (MDS) Visualization')\n",
    "    plt.xlabel('MDS Dimension 1')\n",
    "    plt.ylabel('MDS Dimension 2')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('mds_visualization.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return mds_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Haren\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Haren\\AppData\\Local\\Temp\\ipykernel_15544\\4288057105.py:35: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  color_map = plt.cm.get_cmap('viridis')\n",
      "C:\\Users\\Haren\\AppData\\Local\\Temp\\ipykernel_15544\\4288057105.py:35: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  color_map = plt.cm.get_cmap('viridis')\n",
      "C:\\Users\\Haren\\AppData\\Local\\Temp\\ipykernel_15544\\4288057105.py:35: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  color_map = plt.cm.get_cmap('viridis')\n",
      "C:\\Users\\Haren\\AppData\\Local\\Temp\\ipykernel_15544\\4288057105.py:35: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  color_map = plt.cm.get_cmap('viridis')\n",
      "C:\\Users\\Haren\\AppData\\Local\\Temp\\ipykernel_15544\\4288057105.py:35: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  color_map = plt.cm.get_cmap('viridis')\n",
      "C:\\Users\\Haren\\AppData\\Local\\Temp\\ipykernel_15544\\4288057105.py:35: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  color_map = plt.cm.get_cmap('viridis')\n",
      "C:\\Users\\Haren\\AppData\\Local\\Temp\\ipykernel_15544\\4288057105.py:35: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  color_map = plt.cm.get_cmap('viridis')\n"
     ]
    }
   ],
   "source": [
    "# Main Execution Function\n",
    "def main():\n",
    "    # Image directory (replace with your actual path)\n",
    "    image_dir = './Image Set'\n",
    "    \n",
    "    # Initialize dataset and feature extractor\n",
    "    dataset = ImageDataset(image_dir)\n",
    "    extractor = AlexNetFeatureExtractor()\n",
    "    \n",
    "    # Create data loader\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=len(dataset), shuffle=False\n",
    "    )\n",
    "    \n",
    "    # STEP 1: Prepare Class Labels\n",
    "    def assign_class_label(idx):\n",
    "        if 0 <= idx < 28:\n",
    "            return 0  # Animals\n",
    "        elif 28 <= idx < 64:\n",
    "            return 1  # Objects\n",
    "        elif 64 <= idx < 100:\n",
    "            return 2  # Scenes\n",
    "        elif 100 <= idx < 124:\n",
    "            return 3  # Human Activities\n",
    "        else:\n",
    "            return 4  # Faces\n",
    "    \n",
    "    class_labels = [assign_class_label(i) for i in range(len(dataset))]\n",
    "    \n",
    "    # STEP 1 & 2: Extract Features and Create RDM for each layer\n",
    "    layer_rdms = {}\n",
    "    for layer_name in extractor.layers.keys():\n",
    "        # Get images and extract features\n",
    "        images, _ = next(iter(dataloader))\n",
    "        features = extractor.extract_features(images)[layer_name]\n",
    "        \n",
    "        # STEP 2: Create RDM\n",
    "        rdm = create_rdm(features)\n",
    "        layer_rdms[layer_name] = rdm\n",
    "        \n",
    "        # STEP 3: Visualizations\n",
    "        # Plot RDM\n",
    "        plot_rdm(rdm, layer_name, class_labels)\n",
    "        \n",
    "        # Perform MDS\n",
    "        perform_mds(rdm, class_labels)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
