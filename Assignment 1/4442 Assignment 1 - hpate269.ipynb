{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Refreshing Mathematics\n",
    "Let w ∈ ℝⁿ be an *n*-dimensional column vector, and *f(w)* ∈ ℝ be a function of w. In Lecture 2, we have defined the gradient ∇f(w) ∈ ℝⁿ and Hessian matrix *H* ∈ ℝⁿˣⁿ of f with respect to w.\n",
    "\n",
    "a) Let $f(w) = w^\\top Xb$ where **X** ∈ ℝⁿˣᵖ is an *n×p* matrix, and **b** is a *p*-dimensional column vector. Compute ∇**f(w)** using the definition of gradient.\n",
    "\n",
    "b) Let $f(w) = \\text{tr}(Bww^\\top A)$ where **A, B** ∈ ℝⁿˣⁿ are squared matrices of size *n × n*, and tr(**A**) is the trace of the squared matrix **A**. Using the definition of gradient, compute ∇**f(w)**.\n",
    "\n",
    "c) Let $f(w) = \\text{tr}(Bww^\\top A)$. Compute the Hessian matrix **H** of **f** with respect to **w** using the definition.\n",
    "\n",
    "d) If $A = \\begin{bmatrix} 1 & 1 \\\\ 1 & 2 \\end{bmatrix}$ and $B = \\begin{bmatrix} 2 & -1 \\\\ -1 & 3 \\end{bmatrix}$. Is **f(w)** a convex function? (*Hint: you may use Python/Matlab/R for this question.*)\n",
    "\n",
    "e)In Lecture 5, we have defined the sigmoid function: $\\sigma(a) = \\frac{1}{1+e^{-a}}$. Let $f(w) = \\log(\\sigma(w^\\top x))$ where **log** is the natural logarithm function. Compute ∇**f(w)** using the definition of gradient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear and Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load the training data hw1xtr.dat and hw1ytr.dat into the memory and plot it on one graph. Load the test data hw1xte.dat and hw1yte.dat into the memory and plot it on another graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data hw1xtr.dat and hw1ytr.dat into the memory\n",
    "\n",
    "\n",
    "# Plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data hw1xte.dat and hw1yte.dat into the memory\n",
    "\n",
    "\n",
    "# Plot graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Add a column vector of 1’s to the features, then use the linear regression formula discussed in Lecture 3 to obtain a 2-dimensional weight vector. Plot both the linear regression line and the training data on the same graph. Also, report the average error on the training set using Eq. (1).\n",
    "\n",
    "$$\n",
    "\\text{err} = \\frac{1}{m} \\sum_{i=1}^{m} (w^\\top x_i - y_i)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column vector of 1's to features\n",
    "\n",
    "\n",
    "# Use linear regression formula to obtain 2-dimensional weight vector\n",
    "\n",
    "\n",
    "# Plot linear regression line and training data on graph\n",
    "\n",
    "\n",
    "# Average error on training set using Eq. (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Plot both the regression line and the test data on the same graph. Also report the average error on the test set using Eq. (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot regression line and test data\n",
    "\n",
    "\n",
    "# Average error on test set using Eq. (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implement the 2nd-order polynomial regression by adding new features x<sup>2</sup> to the inputs. Repeat (b) and (c). Compare the training error and test error. Is it a better fit than linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd-order polynomial regression\n",
    "\n",
    "\n",
    "# Repeat steps from b\n",
    "\n",
    "\n",
    "# Repeat steps from c\n",
    "\n",
    "\n",
    "# Compare training error and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YES OR NO IF BETTER FIT THAN LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Implement the 3rd-order polynomial regression by adding new features x<sup>2</sup>, x<sup>3</sup> to the inputs. Repeat (b) and (c). Compare the training error and test error. Is it a better fit than linear regression and 2nd-order polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd-order polynomial regression\n",
    "\n",
    "\n",
    "# Repeat steps from b\n",
    "\n",
    "\n",
    "# Repeat steps from c\n",
    "\n",
    "\n",
    "# Compare training error and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YES OR NO IF BETTER FIT THAN LINEAR REGRESSION AND 2ND-ORDER POLYNOMIAL REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Implement the 4th-order polynomial regression by adding new features x2, x3, x4 to the inputs. Repeat (b) and (c). Compare the training error and test error. Compared with the previous results, which order is the best for fitting the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd-order polynomial regression\n",
    "\n",
    "\n",
    "# Repeat steps from b\n",
    "\n",
    "\n",
    "# Repeat steps from c\n",
    "\n",
    "\n",
    "# Compare training error and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARE TO PREVIOUS RESULTS, CHOOSE WHICH ORDER IS BEST FOR FITTING THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regularization and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Using the training data to implement ℓ<sub>2</sub>-regularized for the 4th-order polynomial regression (page 12 of Lecture 4, note that we do not penalize the bias term w<sub>0</sub>), vary the regularization parameter λ ∈ {0.01, 0.1, 1, 10, 100, 1000}. Plot the training and test error (averaged over all instances) using Eq. (1) as a function of λ (you should use a log10 scale for λ). Which λ is the best for fitting the data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement ℓ2-regularized for the 4th-order polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Plot the value of each weight parameter (including the bias term w0) as a function of λ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot value of each weight parameter as function of λ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a procedure that performs five-fold cross-validation on your training data (page 7\n",
    "of Lecture 4). Use it to determine the best value for λ. Show the average error on the validation\n",
    "set as a function of λ. Is the same as the best λ in (a)? For the best fit, plot the test data and the\n",
    "ℓ<sub>2</sub>-regularized 4th-order polynomial regression line obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCEDURE FOR FIVE-FOLD CROSS-VALIDATION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five-fold cross-validation on your training data\n",
    "\n",
    "\n",
    "# Determine the best value for λ\n",
    "\n",
    "\n",
    "# Average error on the validation set as a function of λ\n",
    "\n",
    "\n",
    "#  Plot test data and the ℓ2-regularized 4th-order polynomial regression line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
